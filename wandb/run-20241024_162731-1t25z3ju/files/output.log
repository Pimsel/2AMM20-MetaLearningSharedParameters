C:\Users\pimde\OneDrive\Documents\GitHub\2AMM20-MetaLearningSharedParameters\finetune.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load("saved_models/spo_model.pth")
C:\Users\pimde\OneDrive\Documents\GitHub\2AMM20-MetaLearningSharedParameters\finetune.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load("saved_models/spo_model.pth")
C:\Users\pimde\anaconda3\envs\2AMM20\Lib\site-packages\torch\functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\TensorShape.cpp:3610.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Gradient for shared_block.0.linear.weight: 5.339716911315918
Gradient for shared_block.0.linear.bias: 8.095667839050293
Gradient for shared_block.1.linear.weight: 28.521757125854492
Gradient for shared_block.1.linear.bias: 2.2468175888061523
Gradient for shared_block.2.linear.weight: 8.373167037963867
Gradient for shared_block.2.linear.bias: 0.6508406400680542
Gradient for shared_block.3.linear.weight: 2.6837406158447266
Gradient for shared_block.3.linear.bias: 0.22055740654468536
Gradient for shared_block.4.linear.weight: 0.9260614514350891
Gradient for shared_block.4.linear.bias: 0.07520920783281326
Gradient for shared_block.5.linear.weight: 0.33763498067855835
Gradient for shared_block.5.linear.bias: 0.026820970699191093
Gradient for shared_block.6.linear.weight: 0.14285027980804443
Gradient for shared_block.6.linear.bias: 0.015239800326526165
Gradient for unique_block.0.linear.weight: 0.9560484290122986
Gradient for unique_block.0.linear.bias: 0.21128463745117188
Gradient for unique_block.1.linear.weight: 14.80770206451416
Gradient for unique_block.1.linear.bias: 2.138843297958374
Gradient for output_layer.weight: 1.3711470365524292
Gradient for output_layer.bias: 0.21739986538887024
Image 1  /1000; epoch 1   /100000 processed.   Gradient for shared_block.0.linear.weight: 10.679433822631836
Gradient for shared_block.0.linear.bias: 16.191335678100586
Gradient for shared_block.1.linear.weight: 57.043514251708984
Gradient for shared_block.1.linear.bias: 4.493635177612305
Gradient for shared_block.2.linear.weight: 16.746334075927734
Gradient for shared_block.2.linear.bias: 1.3016812801361084
Gradient for shared_block.3.linear.weight: 5.367481231689453
Gradient for shared_block.3.linear.bias: 0.4411148130893707
Gradient for shared_block.4.linear.weight: 1.8521229028701782
Gradient for shared_block.4.linear.bias: 0.15041841566562653
Gradient for shared_block.5.linear.weight: 0.6752699613571167
Gradient for shared_block.5.linear.bias: 0.05364194139838219
Gradient for shared_block.6.linear.weight: 0.28570055961608887
Gradient for shared_block.6.linear.bias: 0.03047960065305233
Gradient for unique_block.0.linear.weight: 1.9120968580245972
Gradient for unique_block.0.linear.bias: 0.42256927490234375
Gradient for unique_block.1.linear.weight: 29.61540412902832
Gradient for unique_block.1.linear.bias: 4.277686595916748
Gradient for output_layer.weight: 2.7422940731048584
Gradient for output_layer.bias: 0.4347997307777405
Image 1  /1000; epoch 2   /100000 processed.   Gradient for shared_block.0.linear.weight: 16.019149780273438
Gradient for shared_block.0.linear.bias: 24.287002563476562
Gradient for shared_block.1.linear.weight: 85.56526947021484
Gradient for shared_block.1.linear.bias: 6.740452766418457
Gradient for shared_block.2.linear.weight: 25.1195011138916
Gradient for shared_block.2.linear.bias: 1.9525219202041626
Gradient for shared_block.3.linear.weight: 8.05122184753418
Gradient for shared_block.3.linear.bias: 0.6616722345352173
Gradient for shared_block.4.linear.weight: 2.778184175491333
Gradient for shared_block.4.linear.bias: 0.2256276160478592
Gradient for shared_block.5.linear.weight: 1.0129048824310303
Gradient for shared_block.5.linear.bias: 0.08046291023492813
Gradient for shared_block.6.linear.weight: 0.4285508692264557
Gradient for shared_block.6.linear.bias: 0.04571940004825592
Gradient for unique_block.0.linear.weight: 2.868145227432251
Gradient for unique_block.0.linear.bias: 0.6338539719581604
Gradient for unique_block.1.linear.weight: 44.4231071472168
Gradient for unique_block.1.linear.bias: 6.416529655456543
Gradient for output_layer.weight: 4.113440990447998
Gradient for output_layer.bias: 0.6521996259689331
Image 1  /1000; epoch 3   /100000 processed.   Gradient for shared_block.0.linear.weight: 21.358867645263672
Gradient for shared_block.0.linear.bias: 32.38267135620117
Gradient for shared_block.1.linear.weight: 114.08702850341797
Gradient for shared_block.1.linear.bias: 8.98727035522461
Gradient for shared_block.2.linear.weight: 33.49266815185547
Gradient for shared_block.2.linear.bias: 2.603362560272217
Gradient for shared_block.3.linear.weight: 10.734962463378906
Gradient for shared_block.3.linear.bias: 0.8822296261787415
Gradient for shared_block.4.linear.weight: 3.7042458057403564
Gradient for shared_block.4.linear.bias: 0.30083683133125305
Gradient for shared_block.5.linear.weight: 1.3505399227142334
Gradient for shared_block.5.linear.bias: 0.10728388279676437
Gradient for shared_block.6.linear.weight: 0.5714011192321777
Gradient for shared_block.6.linear.bias: 0.06095920130610466
Gradient for unique_block.0.linear.weight: 3.8241937160491943
Gradient for unique_block.0.linear.bias: 0.8451385498046875
Gradient for unique_block.1.linear.weight: 59.23080825805664
Gradient for unique_block.1.linear.bias: 8.555373191833496
Gradient for output_layer.weight: 5.484588146209717
Gradient for output_layer.bias: 0.869599461555481
Image 1  /1000; epoch 4   /100000 processed.   Gradient for shared_block.0.linear.weight: 26.698583602905273
Gradient for shared_block.0.linear.bias: 40.47834014892578
Gradient for shared_block.1.linear.weight: 142.60877990722656
Gradient for shared_block.1.linear.bias: 11.234086990356445
Gradient for shared_block.2.linear.weight: 41.8658332824707
Gradient for shared_block.2.linear.bias: 3.2542030811309814
Gradient for shared_block.3.linear.weight: 13.418703079223633
Gradient for shared_block.3.linear.bias: 1.1027870178222656
Gradient for shared_block.4.linear.weight: 4.630307197570801
Gradient for shared_block.4.linear.bias: 0.3760460317134857
Gradient for shared_block.5.linear.weight: 1.6881749629974365
Gradient for shared_block.5.linear.bias: 0.1341048628091812
Gradient for shared_block.6.linear.weight: 0.7142514586448669
Gradient for shared_block.6.linear.bias: 0.076199010014534
Gradient for unique_block.0.linear.weight: 4.780242443084717
Gradient for unique_block.0.linear.bias: 1.0564231872558594
Gradient for unique_block.1.linear.weight: 74.03851318359375
Gradient for unique_block.1.linear.bias: 10.69421672821045
Gradient for output_layer.weight: 6.8557353019714355
Gradient for output_layer.bias: 1.0869994163513184
Image 1  /1000; epoch 5   /100000 processed.   Gradient for shared_block.0.linear.weight: 32.038299560546875
Gradient for shared_block.0.linear.bias: 48.574005126953125
Gradient for shared_block.1.linear.weight: 171.1305389404297
Gradient for shared_block.1.linear.bias: 13.480905532836914
Gradient for shared_block.2.linear.weight: 50.2390022277832
Gradient for shared_block.2.linear.bias: 3.905043840408325
Gradient for shared_block.3.linear.weight: 16.10244369506836
Gradient for shared_block.3.linear.bias: 1.3233444690704346
Gradient for shared_block.4.linear.weight: 5.556368350982666
Gradient for shared_block.4.linear.bias: 0.4512552320957184
Gradient for shared_block.5.linear.weight: 2.0258097648620605
Gradient for shared_block.5.linear.bias: 0.16092582046985626
Gradient for shared_block.6.linear.weight: 0.8571017384529114
Gradient for shared_block.6.linear.bias: 0.09143880754709244
Gradient for unique_block.0.linear.weight: 5.736290454864502
Gradient for unique_block.0.linear.bias: 1.2677078247070312
Gradient for unique_block.1.linear.weight: 88.8462142944336
Gradient for unique_block.1.linear.bias: 12.833060264587402
Gradient for output_layer.weight: 8.226881980895996
Gradient for output_layer.bias: 1.3043992519378662
Image 1  /1000; epoch 6   /100000 processed.   Gradient for shared_block.0.linear.weight: 37.37801742553711
Gradient for shared_block.0.linear.bias: 56.669673919677734
Gradient for shared_block.1.linear.weight: 199.6522979736328
Gradient for shared_block.1.linear.bias: 15.727723121643066
Gradient for shared_block.2.linear.weight: 58.61216735839844
Gradient for shared_block.2.linear.bias: 4.55588436126709
Gradient for shared_block.3.linear.weight: 18.786184310913086
Gradient for shared_block.3.linear.bias: 1.543901801109314
Gradient for shared_block.4.linear.weight: 6.4824299812316895
Gradient for shared_block.4.linear.bias: 0.5264644622802734
Gradient for shared_block.5.linear.weight: 2.3634448051452637
Gradient for shared_block.5.linear.bias: 0.1877467930316925
Gradient for shared_block.6.linear.weight: 0.9999520182609558
Gradient for shared_block.6.linear.bias: 0.10667860507965088
Gradient for unique_block.0.linear.weight: 6.692338943481445
Gradient for unique_block.0.linear.bias: 1.4789923429489136
Gradient for unique_block.1.linear.weight: 103.65391540527344
Gradient for unique_block.1.linear.bias: 14.971902847290039
Gradient for output_layer.weight: 9.598029136657715
Gradient for output_layer.bias: 1.5217992067337036
Image 1  /1000; epoch 7   /100000 processed.   Gradient for shared_block.0.linear.weight: 42.717735290527344
Gradient for shared_block.0.linear.bias: 64.76534271240234
Gradient for shared_block.1.linear.weight: 228.17405700683594
Gradient for shared_block.1.linear.bias: 17.97454071044922
Gradient for shared_block.2.linear.weight: 66.98533630371094
Gradient for shared_block.2.linear.bias: 5.206725120544434
Gradient for shared_block.3.linear.weight: 21.469924926757812
Gradient for shared_block.3.linear.bias: 1.764459252357483
Gradient for shared_block.4.linear.weight: 7.408491611480713
Gradient for shared_block.4.linear.bias: 0.6016736626625061
Gradient for shared_block.5.linear.weight: 2.701079845428467
Gradient for shared_block.5.linear.bias: 0.21456776559352875
Gradient for shared_block.6.linear.weight: 1.1428022384643555
Gradient for shared_block.6.linear.bias: 0.12191841006278992
Gradient for unique_block.0.linear.weight: 7.648387432098389
Gradient for unique_block.0.linear.bias: 1.690277099609375
Gradient for unique_block.1.linear.weight: 118.46161651611328
Gradient for unique_block.1.linear.bias: 17.110746383666992
Gradient for output_layer.weight: 10.969176292419434
Gradient for output_layer.bias: 1.7391990423202515
Image 1  /1000; epoch 8   /100000 processed.   Gradient for shared_block.0.linear.weight: 48.05745315551758
Gradient for shared_block.0.linear.bias: 72.86101531982422
Gradient for shared_block.1.linear.weight: 256.69580078125
Gradient for shared_block.1.linear.bias: 20.221357345581055
Gradient for shared_block.2.linear.weight: 75.3584976196289
Gradient for shared_block.2.linear.bias: 5.857565879821777
Gradient for shared_block.3.linear.weight: 24.153663635253906
Gradient for shared_block.3.linear.bias: 1.9850167036056519
Gradient for shared_block.4.linear.weight: 8.334552764892578
Gradient for shared_block.4.linear.bias: 0.6768828630447388
Gradient for shared_block.5.linear.weight: 3.03871488571167
Gradient for shared_block.5.linear.bias: 0.241388738155365
Gradient for shared_block.6.linear.weight: 1.2856526374816895
Gradient for shared_block.6.linear.bias: 0.13715820014476776
Gradient for unique_block.0.linear.weight: 8.604435920715332
Gradient for unique_block.0.linear.bias: 1.9015617370605469
Gradient for unique_block.1.linear.weight: 133.26931762695312
Gradient for unique_block.1.linear.bias: 19.249589920043945
Gradient for output_layer.weight: 12.340323448181152
Gradient for output_layer.bias: 1.9565988779067993
Image 1  /1000; epoch 9   /100000 processed.   Gradient for shared_block.0.linear.weight: 53.39716720581055
Gradient for shared_block.0.linear.bias: 80.95668029785156
Gradient for shared_block.1.linear.weight: 285.2175598144531
Gradient for shared_block.1.linear.bias: 22.468175888061523
Gradient for shared_block.2.linear.weight: 83.7316665649414
Gradient for shared_block.2.linear.bias: 6.508406639099121
Gradient for shared_block.3.linear.weight: 26.837406158447266
Gradient for shared_block.3.linear.bias: 2.2055740356445312
Gradient for shared_block.4.linear.weight: 9.260614395141602
Gradient for shared_block.4.linear.bias: 0.7520920634269714
Gradient for shared_block.5.linear.weight: 3.376349687576294
Gradient for shared_block.5.linear.bias: 0.2682097256183624
Gradient for shared_block.6.linear.weight: 1.4285029172897339
Gradient for shared_block.6.linear.bias: 0.1523980051279068
Gradient for unique_block.0.linear.weight: 9.560484886169434
Gradient for unique_block.0.linear.bias: 2.1128463745117188
Gradient for unique_block.1.linear.weight: 148.0770263671875
Gradient for unique_block.1.linear.bias: 21.388431549072266
Gradient for output_layer.weight: 13.711470603942871
Gradient for output_layer.bias: 2.1739988327026367
Image 1  /1000; epoch 10  /100000 processed.   Gradient for shared_block.0.linear.weight: 58.73688888549805
Gradient for shared_block.0.linear.bias: 89.0523452758789
Gradient for shared_block.1.linear.weight: 313.73931884765625
Gradient for shared_block.1.linear.bias: 24.71499252319336
Gradient for shared_block.2.linear.weight: 92.1048355102539
Gradient for shared_block.2.linear.bias: 7.159246921539307
Gradient for shared_block.3.linear.weight: 29.52114486694336
Gradient for shared_block.3.linear.bias: 2.4261314868927
Gradient for shared_block.4.linear.weight: 10.186675071716309
Gradient for shared_block.4.linear.bias: 0.8273012638092041
Gradient for shared_block.5.linear.weight: 3.713984727859497
Gradient for shared_block.5.linear.bias: 0.2950306832790375
Gradient for shared_block.6.linear.weight: 1.5713530778884888
Gradient for shared_block.6.linear.bias: 0.16763781011104584
Gradient for unique_block.0.linear.weight: 10.516532897949219
Gradient for unique_block.0.linear.bias: 2.3241310119628906
Gradient for unique_block.1.linear.weight: 162.8847198486328
Gradient for unique_block.1.linear.bias: 23.52727508544922
Gradient for output_layer.weight: 15.08261775970459
Gradient for output_layer.bias: 2.3913986682891846
Image 1  /1000; epoch 11  /100000 processed.   Gradient for shared_block.0.linear.weight: 64.07659912109375
Gradient for shared_block.0.linear.bias: 97.14802551269531
Gradient for shared_block.1.linear.weight: 342.2610778808594
Gradient for shared_block.1.linear.bias: 26.961811065673828
Gradient for shared_block.2.linear.weight: 100.4780044555664
Gradient for shared_block.2.linear.bias: 7.81008768081665
Gradient for shared_block.3.linear.weight: 32.20488739013672
Gradient for shared_block.3.linear.bias: 2.646688938140869
Gradient for shared_block.4.linear.weight: 11.112736701965332
Gradient for shared_block.4.linear.bias: 0.9025104641914368
Gradient for shared_block.5.linear.weight: 4.051619529724121
Gradient for shared_block.5.linear.bias: 0.3218516409397125
Gradient for shared_block.6.linear.weight: 1.7142034769058228
Gradient for shared_block.6.linear.bias: 0.18287761509418488
Gradient for unique_block.0.linear.weight: 11.472580909729004
Gradient for unique_block.0.linear.bias: 2.5354156494140625
Gradient for unique_block.1.linear.weight: 177.6924285888672
Gradient for unique_block.1.linear.bias: 25.666118621826172
Gradient for output_layer.weight: 16.453763961791992
Gradient for output_layer.bias: 2.6087985038757324
Image 1  /1000; epoch 12  /100000 processed.   Gradient for shared_block.0.linear.weight: 69.41631317138672
Gradient for shared_block.0.linear.bias: 105.24368286132812
Gradient for shared_block.1.linear.weight: 370.7828369140625
Gradient for shared_block.1.linear.bias: 29.208627700805664
Gradient for shared_block.2.linear.weight: 108.85116577148438
Gradient for shared_block.2.linear.bias: 8.460928916931152
Gradient for shared_block.3.linear.weight: 34.88862609863281
Gradient for shared_block.3.linear.bias: 2.867246150970459
Gradient for shared_block.4.linear.weight: 12.038799285888672
Gradient for shared_block.4.linear.bias: 0.9777196645736694
Gradient for shared_block.5.linear.weight: 4.389254570007324
Gradient for shared_block.5.linear.bias: 0.3486725986003876
Gradient for shared_block.6.linear.weight: 1.8570537567138672
Gradient for shared_block.6.linear.bias: 0.19811740517616272
Gradient for unique_block.0.linear.weight: 12.428628921508789
Gradient for unique_block.0.linear.bias: 2.7467002868652344
Gradient for unique_block.1.linear.weight: 192.50013732910156
Gradient for unique_block.1.linear.bias: 27.804962158203125
Gradient for output_layer.weight: 17.82491111755371
Gradient for output_layer.bias: 2.8261983394622803
Image 1  /1000; epoch 13  /100000 processed.   Gradient for shared_block.0.linear.weight: 74.75603485107422
Gradient for shared_block.0.linear.bias: 113.33934783935547
Gradient for shared_block.1.linear.weight: 399.3045959472656
Gradient for shared_block.1.linear.bias: 31.455446243286133
Gradient for shared_block.2.linear.weight: 117.22433471679688
Gradient for shared_block.2.linear.bias: 9.11176872253418
Gradient for shared_block.3.linear.weight: 37.572364807128906
Gradient for shared_block.3.linear.bias: 3.087803602218628
Gradient for shared_block.4.linear.weight: 12.964859962463379
Gradient for shared_block.4.linear.bias: 1.0529288053512573
Gradient for shared_block.5.linear.weight: 4.726889610290527
Gradient for shared_block.5.linear.bias: 0.375493586063385
Gradient for shared_block.6.linear.weight: 1.9999040365219116
Gradient for shared_block.6.linear.bias: 0.21335721015930176
Gradient for unique_block.0.linear.weight: 13.38467788696289
Gradient for unique_block.0.linear.bias: 2.9579849243164062
Gradient for unique_block.1.linear.weight: 207.30783081054688
Gradient for unique_block.1.linear.bias: 29.943805694580078
Gradient for output_layer.weight: 19.19605827331543
Gradient for output_layer.bias: 3.0435984134674072
Image 1  /1000; epoch 14  /100000 processed.   Gradient for shared_block.0.linear.weight: 80.09574890136719
Gradient for shared_block.0.linear.bias: 121.43502044677734
Gradient for shared_block.1.linear.weight: 427.8263244628906
Gradient for shared_block.1.linear.bias: 33.70226287841797
Gradient for shared_block.2.linear.weight: 125.59750366210938
Gradient for shared_block.2.linear.bias: 9.762609481811523
Gradient for shared_block.3.linear.weight: 40.256107330322266
Gradient for shared_block.3.linear.bias: 3.308361053466797
Gradient for shared_block.4.linear.weight: 13.890920639038086
Gradient for shared_block.4.linear.bias: 1.1281380653381348
Gradient for shared_block.5.linear.weight: 5.0645246505737305
Gradient for shared_block.5.linear.bias: 0.40231454372406006
Gradient for shared_block.6.linear.weight: 2.142754077911377
Gradient for shared_block.6.linear.bias: 0.2285970002412796
Gradient for unique_block.0.linear.weight: 14.340726852416992
Gradient for unique_block.0.linear.bias: 3.169269561767578
Gradient for unique_block.1.linear.weight: 222.11553955078125
Gradient for unique_block.1.linear.bias: 32.08264923095703
Gradient for output_layer.weight: 20.56720542907715
Gradient for output_layer.bias: 3.260998010635376
Image 1  /1000; epoch 15  /100000 processed.   Gradient for shared_block.0.linear.weight: 85.43547058105469
Gradient for shared_block.0.linear.bias: 129.5306854248047
Gradient for shared_block.1.linear.weight: 456.3481140136719
Gradient for shared_block.1.linear.bias: 35.94908142089844
Gradient for shared_block.2.linear.weight: 133.97067260742188
Gradient for shared_block.2.linear.bias: 10.413450241088867
Gradient for shared_block.3.linear.weight: 42.939849853515625
Gradient for shared_block.3.linear.bias: 3.528918504714966
Gradient for shared_block.4.linear.weight: 14.816983222961426
Gradient for shared_block.4.linear.bias: 1.2033473253250122
Gradient for shared_block.5.linear.weight: 5.402159690856934
Gradient for shared_block.5.linear.bias: 0.4291355311870575
Gradient for shared_block.6.linear.weight: 2.285604476928711
Gradient for shared_block.6.linear.bias: 0.24383680522441864
Gradient for unique_block.0.linear.weight: 15.296774864196777
Gradient for unique_block.0.linear.bias: 3.38055419921875
Gradient for unique_block.1.linear.weight: 236.92323303222656
Gradient for unique_block.1.linear.bias: 34.221492767333984
Gradient for output_layer.weight: 21.938352584838867
Gradient for output_layer.bias: 3.478397846221924
Image 1  /1000; epoch 16  /100000 processed.   Gradient for shared_block.0.linear.weight: 90.77518463134766
Gradient for shared_block.0.linear.bias: 137.62635803222656
Gradient for shared_block.1.linear.weight: 484.869873046875
Gradient for shared_block.1.linear.bias: 38.195899963378906
Gradient for shared_block.2.linear.weight: 142.34384155273438
Gradient for shared_block.2.linear.bias: 11.064291000366211
Gradient for shared_block.3.linear.weight: 45.62358856201172
Gradient for shared_block.3.linear.bias: 3.7494759559631348
Gradient for shared_block.4.linear.weight: 15.743043899536133
Gradient for shared_block.4.linear.bias: 1.2785564661026
Gradient for shared_block.5.linear.weight: 5.739794731140137
Gradient for shared_block.5.linear.bias: 0.45595648884773254
Gradient for shared_block.6.linear.weight: 2.428454875946045
Gradient for shared_block.6.linear.bias: 0.2590765953063965
Gradient for unique_block.0.linear.weight: 16.252824783325195
Gradient for unique_block.0.linear.bias: 3.5918385982513428
Gradient for unique_block.1.linear.weight: 251.73094177246094
Gradient for unique_block.1.linear.bias: 36.36033630371094
Gradient for output_layer.weight: 23.309499740600586
Gradient for output_layer.bias: 3.6957976818084717
Image 1  /1000; epoch 17  /100000 processed.   Gradient for shared_block.0.linear.weight: 96.11489868164062
Gradient for shared_block.0.linear.bias: 145.72201538085938
Gradient for shared_block.1.linear.weight: 513.3916015625
Gradient for shared_block.1.linear.bias: 40.44271469116211
Gradient for shared_block.2.linear.weight: 150.71701049804688
Gradient for shared_block.2.linear.bias: 11.715131759643555
Gradient for shared_block.3.linear.weight: 48.30733108520508
Gradient for shared_block.3.linear.bias: 3.9700334072113037
Gradient for shared_block.4.linear.weight: 16.669105529785156
Gradient for shared_block.4.linear.bias: 1.3537657260894775
Gradient for shared_block.5.linear.weight: 6.07742977142334
Gradient for shared_block.5.linear.bias: 0.48277747631073
Gradient for shared_block.6.linear.weight: 2.5713050365448
Gradient for shared_block.6.linear.bias: 0.2743164002895355
Gradient for unique_block.0.linear.weight: 17.208871841430664
Gradient for unique_block.0.linear.bias: 3.8031232357025146
Gradient for unique_block.1.linear.weight: 266.53863525390625
Gradient for unique_block.1.linear.bias: 38.49917984008789
Gradient for output_layer.weight: 24.680646896362305
Gradient for output_layer.bias: 3.9131977558135986
Image 1  /1000; epoch 18  /100000 processed.   Gradient for shared_block.0.linear.weight: 101.4546127319336
Gradient for shared_block.0.linear.bias: 153.81768798828125
Gradient for shared_block.1.linear.weight: 541.9133911132812
Gradient for shared_block.1.linear.bias: 42.68953323364258
Gradient for shared_block.2.linear.weight: 159.0901641845703
Gradient for shared_block.2.linear.bias: 12.365972518920898
Gradient for shared_block.3.linear.weight: 50.99106979370117
Gradient for shared_block.3.linear.bias: 4.190590858459473
Gradient for shared_block.4.linear.weight: 17.59516716003418
Gradient for shared_block.4.linear.bias: 1.4289748668670654
Gradient for shared_block.5.linear.weight: 6.415064334869385
Gradient for shared_block.5.linear.bias: 0.509598433971405
Gradient for shared_block.6.linear.weight: 2.714155435562134
Gradient for shared_block.6.linear.bias: 0.28955620527267456
Gradient for unique_block.0.linear.weight: 18.164920806884766
Gradient for unique_block.0.linear.bias: 4.014408111572266
Gradient for unique_block.1.linear.weight: 281.3463439941406
Gradient for unique_block.1.linear.bias: 40.638023376464844
Gradient for output_layer.weight: 26.05179214477539
Gradient for output_layer.bias: 4.1305975914001465
Image 1  /1000; epoch 19  /100000 processed.   Gradient for shared_block.0.linear.weight: 106.7943344116211
Gradient for shared_block.0.linear.bias: 161.91336059570312
Gradient for shared_block.1.linear.weight: 570.4351196289062
Gradient for shared_block.1.linear.bias: 44.93635177612305
Gradient for shared_block.2.linear.weight: 167.4633331298828
Gradient for shared_block.2.linear.bias: 13.016812324523926
Gradient for shared_block.3.linear.weight: 53.67481231689453
Gradient for shared_block.3.linear.bias: 4.4111480712890625
Gradient for shared_block.4.linear.weight: 18.521228790283203
Gradient for shared_block.4.linear.bias: 1.5041841268539429
Gradient for shared_block.5.linear.weight: 6.752699851989746
Gradient for shared_block.5.linear.bias: 0.5364194512367249
Gradient for shared_block.6.linear.weight: 2.8570058345794678
Gradient for shared_block.6.linear.bias: 0.3047960102558136
Gradient for unique_block.0.linear.weight: 19.120969772338867
Gradient for unique_block.0.linear.bias: 4.2256927490234375
Gradient for unique_block.1.linear.weight: 296.154052734375
Gradient for unique_block.1.linear.bias: 42.7768669128418
Gradient for output_layer.weight: 27.422941207885742
Gradient for output_layer.bias: 4.347997665405273
Image 1  /1000; epoch 20  /100000 processed.   Gradient for shared_block.0.linear.weight: 112.1340560913086
Gradient for shared_block.0.linear.bias: 170.009033203125
Gradient for shared_block.1.linear.weight: 598.9568481445312
Gradient for shared_block.1.linear.bias: 47.183170318603516
Gradient for shared_block.2.linear.weight: 175.8365020751953
Gradient for shared_block.2.linear.bias: 13.66765308380127
Gradient for shared_block.3.linear.weight: 56.358551025390625
Gradient for shared_block.3.linear.bias: 4.631705284118652
Gradient for shared_block.4.linear.weight: 19.447290420532227
Gradient for shared_block.4.linear.bias: 1.5793933868408203
Gradient for shared_block.5.linear.weight: 7.090334415435791
Gradient for shared_block.5.linear.bias: 0.5632403492927551
Gradient for shared_block.6.linear.weight: 2.9998559951782227
Gradient for shared_block.6.linear.bias: 0.32003581523895264
Gradient for unique_block.0.linear.weight: 20.077016830444336
Gradient for unique_block.0.linear.bias: 4.436977386474609
Gradient for unique_block.1.linear.weight: 310.96173095703125
Gradient for unique_block.1.linear.bias: 44.91571044921875
Gradient for output_layer.weight: 28.79408836364746
Gradient for output_layer.bias: 4.5653977394104
Image 1  /1000; epoch 21  /100000 processed.   Gradient for shared_block.0.linear.weight: 117.47377014160156
Gradient for shared_block.0.linear.bias: 178.1046905517578
Gradient for shared_block.1.linear.weight: 627.4786376953125
Gradient for shared_block.1.linear.bias: 49.429988861083984
Gradient for shared_block.2.linear.weight: 184.2096710205078
Gradient for shared_block.2.linear.bias: 14.318493843078613
Gradient for shared_block.3.linear.weight: 59.04228973388672
Gradient for shared_block.3.linear.bias: 4.8522629737854
Gradient for shared_block.4.linear.weight: 20.373350143432617
Gradient for shared_block.4.linear.bias: 1.6546025276184082
Gradient for shared_block.5.linear.weight: 7.427969455718994
Gradient for shared_block.5.linear.bias: 0.590061366558075
Gradient for shared_block.6.linear.weight: 3.1427063941955566
Gradient for shared_block.6.linear.bias: 0.3352756202220917
Gradient for unique_block.0.linear.weight: 21.033065795898438
Gradient for unique_block.0.linear.bias: 4.648262023925781
Gradient for unique_block.1.linear.weight: 325.7694396972656
Gradient for unique_block.1.linear.bias: 47.05455017089844
Gradient for output_layer.weight: 30.16523551940918
Gradient for output_layer.bias: 4.782797336578369
Image 1  /1000; epoch 22  /100000 processed.   Gradient for shared_block.0.linear.weight: 122.81348419189453
Gradient for shared_block.0.linear.bias: 186.20037841796875
Gradient for shared_block.1.linear.weight: 656.0003662109375
Gradient for shared_block.1.linear.bias: 51.67680358886719
Gradient for shared_block.2.linear.weight: 192.5828399658203
Gradient for shared_block.2.linear.bias: 14.969334602355957
Gradient for shared_block.3.linear.weight: 61.72603225708008
Gradient for shared_block.3.linear.bias: 5.072820663452148
Gradient for shared_block.4.linear.weight: 21.29941177368164
Gradient for shared_block.4.linear.bias: 1.729811668395996
Gradient for shared_block.5.linear.weight: 7.765604496002197
Gradient for shared_block.5.linear.bias: 0.61688232421875
Gradient for shared_block.6.linear.weight: 3.2855565547943115
Gradient for shared_block.6.linear.bias: 0.3505154252052307
Gradient for unique_block.0.linear.weight: 21.98911476135254
Gradient for unique_block.0.linear.bias: 4.859546184539795
Gradient for unique_block.1.linear.weight: 340.5771484375
Gradient for unique_block.1.linear.bias: 49.193397521972656
Gradient for output_layer.weight: 31.5363826751709
Gradient for output_layer.bias: 5.000197410583496
Image 1  /1000; epoch 23  /100000 processed.   Gradient for shared_block.0.linear.weight: 128.1531982421875
Gradient for shared_block.0.linear.bias: 194.2960205078125
Gradient for shared_block.1.linear.weight: 684.5221557617188
Gradient for shared_block.1.linear.bias: 53.923622131347656
Gradient for shared_block.2.linear.weight: 200.9560089111328
Gradient for shared_block.2.linear.bias: 15.6201753616333
Gradient for shared_block.3.linear.weight: 64.40977478027344
Gradient for shared_block.3.linear.bias: 5.293377876281738
Gradient for shared_block.4.linear.weight: 22.225473403930664
Gradient for shared_block.4.linear.bias: 1.8050209283828735
Gradient for shared_block.5.linear.weight: 8.103239059448242
Gradient for shared_block.5.linear.bias: 0.643703281879425
Gradient for shared_block.6.linear.weight: 3.4284069538116455
Gradient for shared_block.6.linear.bias: 0.36575520038604736
Gradient for unique_block.0.linear.weight: 22.945161819458008
Gradient for unique_block.0.linear.bias: 5.070831298828125
Gradient for unique_block.1.linear.weight: 355.3848571777344
Gradient for unique_block.1.linear.bias: 51.33224105834961
Gradient for output_layer.weight: 32.907527923583984
Gradient for output_layer.bias: 5.217597484588623
Image 1  /1000; epoch 24  /100000 processed.   Gradient for shared_block.0.linear.weight: 133.492919921875
Gradient for shared_block.0.linear.bias: 202.39169311523438
Gradient for shared_block.1.linear.weight: 713.0438842773438
Gradient for shared_block.1.linear.bias: 56.170440673828125
Gradient for shared_block.2.linear.weight: 209.3291778564453
Gradient for shared_block.2.linear.bias: 16.27101707458496
Gradient for shared_block.3.linear.weight: 67.09351348876953
Gradient for shared_block.3.linear.bias: 5.513935089111328
Gradient for shared_block.4.linear.weight: 23.151535034179688
Gradient for shared_block.4.linear.bias: 1.880230188369751
Gradient for shared_block.5.linear.weight: 8.440874099731445
Gradient for shared_block.5.linear.bias: 0.6705242991447449
Gradient for shared_block.6.linear.weight: 3.5712571144104004
Gradient for shared_block.6.linear.bias: 0.3809950053691864
Gradient for unique_block.0.linear.weight: 23.90121078491211
Gradient for unique_block.0.linear.bias: 5.282115459442139
Gradient for unique_block.1.linear.weight: 370.19256591796875
Gradient for unique_block.1.linear.bias: 53.47108459472656
Gradient for output_layer.weight: 34.2786750793457
Gradient for output_layer.bias: 5.434997081756592
Image 1  /1000; epoch 25  /100000 processed.   Gradient for shared_block.0.linear.weight: 138.83262634277344
Gradient for shared_block.0.linear.bias: 210.48736572265625
Gradient for shared_block.1.linear.weight: 741.565673828125
Gradient for shared_block.1.linear.bias: 58.41725540161133
Gradient for shared_block.2.linear.weight: 217.70233154296875
Gradient for shared_block.2.linear.bias: 16.921857833862305
Gradient for shared_block.3.linear.weight: 69.77725219726562
Gradient for shared_block.3.linear.bias: 5.734492778778076
Gradient for shared_block.4.linear.weight: 24.077598571777344
Gradient for shared_block.4.linear.bias: 1.9554393291473389
Gradient for shared_block.5.linear.weight: 8.778509140014648
Gradient for shared_block.5.linear.bias: 0.6973452568054199
Gradient for shared_block.6.linear.weight: 3.7141075134277344
Gradient for shared_block.6.linear.bias: 0.39623481035232544
Gradient for unique_block.0.linear.weight: 24.85725975036621
Gradient for unique_block.0.linear.bias: 5.493400573730469
Gradient for unique_block.1.linear.weight: 385.000244140625
Gradient for unique_block.1.linear.bias: 55.60992431640625
Gradient for output_layer.weight: 35.64982223510742
Gradient for output_layer.bias: 5.652397155761719
Image 1  /1000; epoch 26  /100000 processed.   Gradient for shared_block.0.linear.weight: 144.17234802246094
Gradient for shared_block.0.linear.bias: 218.58303833007812
Gradient for shared_block.1.linear.weight: 770.08740234375
Gradient for shared_block.1.linear.bias: 60.6640739440918
Gradient for shared_block.2.linear.weight: 226.07550048828125
Gradient for shared_block.2.linear.bias: 17.572696685791016
Gradient for shared_block.3.linear.weight: 72.46099090576172
Gradient for shared_block.3.linear.bias: 5.955049991607666
Gradient for shared_block.4.linear.weight: 25.0036563873291
Gradient for shared_block.4.linear.bias: 2.0306484699249268
Gradient for shared_block.5.linear.weight: 9.116144180297852
Gradient for shared_block.5.linear.bias: 0.724166214466095
Gradient for shared_block.6.linear.weight: 3.8569579124450684
Gradient for shared_block.6.linear.bias: 0.4114746153354645
Gradient for unique_block.0.linear.weight: 25.813308715820312
Gradient for unique_block.0.linear.bias: 5.704685211181641
Gradient for unique_block.1.linear.weight: 399.8079528808594
Gradient for unique_block.1.linear.bias: 57.7487678527832
Gradient for output_layer.weight: 37.02096939086914
Gradient for output_layer.bias: 5.869797229766846
Image 1  /1000; epoch 27  /100000 processed.   Gradient for shared_block.0.linear.weight: 149.51206970214844
Gradient for shared_block.0.linear.bias: 226.67869567871094
Gradient for shared_block.1.linear.weight: 798.6091918945312
Gradient for shared_block.1.linear.bias: 62.910892486572266
Gradient for shared_block.2.linear.weight: 234.44866943359375
Gradient for shared_block.2.linear.bias: 18.22353744506836
Gradient for shared_block.3.linear.weight: 75.14472961425781
Gradient for shared_block.3.linear.bias: 6.175607681274414
Gradient for shared_block.4.linear.weight: 25.929719924926758
Gradient for shared_block.4.linear.bias: 2.1058576107025146
Gradient for shared_block.5.linear.weight: 9.453779220581055
Gradient for shared_block.5.linear.bias: 0.75098717212677
Gradient for shared_block.6.linear.weight: 3.9998080730438232
Gradient for shared_block.6.linear.bias: 0.4267144203186035
Gradient for unique_block.0.linear.weight: 26.76935577392578
Gradient for unique_block.0.linear.bias: 5.915969371795654
Gradient for unique_block.1.linear.weight: 414.61566162109375
Gradient for unique_block.1.linear.bias: 59.887611389160156
Gradient for output_layer.weight: 38.39211654663086
Gradient for output_layer.bias: 6.0871968269348145
Image 1  /1000; epoch 28  /100000 processed.   Gradient for shared_block.0.linear.weight: 154.85179138183594
Gradient for shared_block.0.linear.bias: 234.77438354492188
Gradient for shared_block.1.linear.weight: 827.130859375
Gradient for shared_block.1.linear.bias: 65.15771484375
Gradient for shared_block.2.linear.weight: 242.82183837890625
Gradient for shared_block.2.linear.bias: 18.874378204345703
Gradient for shared_block.3.linear.weight: 77.82847595214844
Gradient for shared_block.3.linear.bias: 6.396164894104004
Gradient for shared_block.4.linear.weight: 26.85578155517578
Gradient for shared_block.4.linear.bias: 2.1810669898986816
Gradient for shared_block.5.linear.weight: 9.791414260864258
Gradient for shared_block.5.linear.bias: 0.7778081893920898
Gradient for shared_block.6.linear.weight: 4.142658233642578
Gradient for shared_block.6.linear.bias: 0.44195422530174255
Gradient for unique_block.0.linear.weight: 27.725404739379883
Gradient for unique_block.0.linear.bias: 6.127254009246826
Gradient for unique_block.1.linear.weight: 429.4233703613281
Gradient for unique_block.1.linear.bias: 62.026458740234375
Gradient for output_layer.weight: 39.76326370239258
Gradient for output_layer.bias: 6.304596900939941
Image 1  /1000; epoch 29  /100000 processed.   Gradient for shared_block.0.linear.weight: 160.19149780273438
Gradient for shared_block.0.linear.bias: 242.8700408935547
Gradient for shared_block.1.linear.weight: 855.6526489257812
Gradient for shared_block.1.linear.bias: 67.40452575683594
Gradient for shared_block.2.linear.weight: 251.19500732421875
Gradient for shared_block.2.linear.bias: 19.525218963623047
Gradient for shared_block.3.linear.weight: 80.51221466064453
Gradient for shared_block.3.linear.bias: 6.616722106933594
Gradient for shared_block.4.linear.weight: 27.781841278076172
Gradient for shared_block.4.linear.bias: 2.2562761306762695
Gradient for shared_block.5.linear.weight: 10.129049301147461
Gradient for shared_block.5.linear.bias: 0.8046291470527649
Gradient for shared_block.6.linear.weight: 4.285508155822754
Gradient for shared_block.6.linear.bias: 0.4571940004825592
Gradient for unique_block.0.linear.weight: 28.681453704833984
Gradient for unique_block.0.linear.bias: 6.338539123535156
Gradient for unique_block.1.linear.weight: 444.2310791015625
Gradient for unique_block.1.linear.bias: 64.16529846191406
Gradient for output_layer.weight: 41.1344108581543
Gradient for output_layer.bias: 6.521996974945068
Image 1  /1000; epoch 30  /100000 processed.   Gradient for shared_block.0.linear.weight: 165.5312042236328
Gradient for shared_block.0.linear.bias: 250.96571350097656
Gradient for shared_block.1.linear.weight: 884.1744384765625
Gradient for shared_block.1.linear.bias: 69.6513442993164
Gradient for shared_block.2.linear.weight: 259.56817626953125
Gradient for shared_block.2.linear.bias: 20.17605972290039
Gradient for shared_block.3.linear.weight: 83.19595336914062
Gradient for shared_block.3.linear.bias: 6.837279796600342
Gradient for shared_block.4.linear.weight: 28.707904815673828
Gradient for shared_block.4.linear.bias: 2.3314852714538574
Gradient for shared_block.5.linear.weight: 10.466684341430664
Gradient for shared_block.5.linear.bias: 0.8314500451087952
Gradient for shared_block.6.linear.weight: 4.428359031677246
Gradient for shared_block.6.linear.bias: 0.47243383526802063
Gradient for unique_block.0.linear.weight: 29.637502670288086
Gradient for unique_block.0.linear.bias: 6.549823760986328
Gradient for unique_block.1.linear.weight: 459.03875732421875
Gradient for unique_block.1.linear.bias: 66.30414581298828
Gradient for output_layer.weight: 42.505558013916016
Gradient for output_layer.bias: 6.739396572113037
Image 1  /1000; epoch 31  /100000 processed.   Gradient for shared_block.0.linear.weight: 170.87094116210938
Gradient for shared_block.0.linear.bias: 259.0613708496094
Gradient for shared_block.1.linear.weight: 912.6962280273438
Gradient for shared_block.1.linear.bias: 71.89816284179688
Gradient for shared_block.2.linear.weight: 267.94134521484375
Gradient for shared_block.2.linear.bias: 20.826900482177734
Gradient for shared_block.3.linear.weight: 85.87969970703125
Gradient for shared_block.3.linear.bias: 7.057837009429932
Gradient for shared_block.4.linear.weight: 29.63396644592285
Gradient for shared_block.4.linear.bias: 2.4066946506500244
Gradient for shared_block.5.linear.weight: 10.804319381713867
Gradient for shared_block.5.linear.bias: 0.858271062374115
Gradient for shared_block.6.linear.weight: 4.57120943069458
Gradient for shared_block.6.linear.bias: 0.4876736104488373
Gradient for unique_block.0.linear.weight: 30.593549728393555
Gradient for unique_block.0.linear.bias: 6.7611083984375
Gradient for unique_block.1.linear.weight: 473.8464660644531
Gradient for unique_block.1.linear.bias: 68.44298553466797
Gradient for output_layer.weight: 43.876705169677734
Gradient for output_layer.bias: 6.956796646118164
Image 1  /1000; epoch 32  /100000 processed.   Gradient for shared_block.0.linear.weight: 176.2106475830078
Gradient for shared_block.0.linear.bias: 267.15704345703125
Gradient for shared_block.1.linear.weight: 941.2179565429688
Gradient for shared_block.1.linear.bias: 74.14498138427734
Gradient for shared_block.2.linear.weight: 276.31451416015625
Gradient for shared_block.2.linear.bias: 21.477741241455078
Gradient for shared_block.3.linear.weight: 88.56343841552734
Gradient for shared_block.3.linear.bias: 7.2783942222595215
Gradient for shared_block.4.linear.weight: 30.560028076171875
Gradient for shared_block.4.linear.bias: 2.4819037914276123
Gradient for shared_block.5.linear.weight: 11.14195442199707
Gradient for shared_block.5.linear.bias: 0.88509202003479
Gradient for shared_block.6.linear.weight: 4.714059352874756
Gradient for shared_block.6.linear.bias: 0.5029134154319763
Gradient for unique_block.0.linear.weight: 31.549598693847656
Gradient for unique_block.0.linear.bias: 6.972393035888672
Gradient for unique_block.1.linear.weight: 488.6541748046875
Gradient for unique_block.1.linear.bias: 70.58183288574219
Gradient for output_layer.weight: 45.24785232543945
Gradient for output_layer.bias: 7.174196243286133
Image 1  /1000; epoch 33  /100000 processed.   Gradient for shared_block.0.linear.weight: 181.5503692626953
Gradient for shared_block.0.linear.bias: 275.2527160644531
Gradient for shared_block.1.linear.weight: 969.73974609375
Gradient for shared_block.1.linear.bias: 76.39179992675781
Gradient for shared_block.2.linear.weight: 284.68768310546875
Gradient for shared_block.2.linear.bias: 22.128582000732422
Gradient for shared_block.3.linear.weight: 91.24717712402344
Gradient for shared_block.3.linear.bias: 7.498951435089111
Gradient for shared_block.4.linear.weight: 31.486087799072266
Gradient for shared_block.4.linear.bias: 2.5571129322052
Gradient for shared_block.5.linear.weight: 11.479589462280273
Gradient for shared_block.5.linear.bias: 0.9119130373001099
Gradient for shared_block.6.linear.weight: 4.85690975189209
Gradient for shared_block.6.linear.bias: 0.518153190612793
Gradient for unique_block.0.linear.weight: 32.505645751953125
Gradient for unique_block.0.linear.bias: 7.183677673339844
Gradient for unique_block.1.linear.weight: 503.4618835449219
Gradient for unique_block.1.linear.bias: 72.72067260742188
Gradient for output_layer.weight: 46.61899948120117
Gradient for output_layer.bias: 7.39159631729126
Image 1  /1000; epoch 34  /100000 processed.   Gradient for shared_block.0.linear.weight: 186.8900909423828
Gradient for shared_block.0.linear.bias: 283.348388671875
Gradient for shared_block.1.linear.weight: 998.2614135742188
Gradient for shared_block.1.linear.bias: 78.63861846923828
Gradient for shared_block.2.linear.weight: 293.06085205078125
Gradient for shared_block.2.linear.bias: 22.779422760009766
Gradient for shared_block.3.linear.weight: 93.93091583251953
Gradient for shared_block.3.linear.bias: 7.719509124755859
Gradient for shared_block.4.linear.weight: 32.41215133666992
Gradient for shared_block.4.linear.bias: 2.632322311401367
Gradient for shared_block.5.linear.weight: 11.817224502563477
Gradient for shared_block.5.linear.bias: 0.9387339949607849
Gradient for shared_block.6.linear.weight: 4.999760150909424
Gradient for shared_block.6.linear.bias: 0.5333930253982544
Gradient for unique_block.0.linear.weight: 33.46169662475586
Gradient for unique_block.0.linear.bias: 7.394962310791016
Gradient for unique_block.1.linear.weight: 518.2695922851562
Gradient for unique_block.1.linear.bias: 74.8595199584961
Gradient for output_layer.weight: 47.99014663696289
Gradient for output_layer.bias: 7.608996391296387
Image 1  /1000; epoch 35  /100000 processed.   Gradient for shared_block.0.linear.weight: 192.22979736328125
Gradient for shared_block.0.linear.bias: 291.4440612792969
Gradient for shared_block.1.linear.weight: 1026.783203125
Gradient for shared_block.1.linear.bias: 80.88543701171875
Gradient for shared_block.2.linear.weight: 301.43402099609375
Gradient for shared_block.2.linear.bias: 23.430261611938477
Gradient for shared_block.3.linear.weight: 96.61465454101562
Gradient for shared_block.3.linear.bias: 7.940066814422607
Gradient for shared_block.4.linear.weight: 33.33821105957031
Gradient for shared_block.4.linear.bias: 2.707531452178955
Gradient for shared_block.5.linear.weight: 12.15485954284668
Gradient for shared_block.5.linear.bias: 0.96555495262146
Gradient for shared_block.6.linear.weight: 5.142610549926758
Gradient for shared_block.6.linear.bias: 0.548632800579071
Gradient for unique_block.0.linear.weight: 34.41774368286133
Gradient for unique_block.0.linear.bias: 7.6062469482421875
Gradient for unique_block.1.linear.weight: 533.0772705078125
Gradient for unique_block.1.linear.bias: 76.99836730957031
Gradient for output_layer.weight: 49.361289978027344
Gradient for output_layer.bias: 7.826396465301514
Image 1  /1000; epoch 36  /100000 processed.   Gradient for shared_block.0.linear.weight: 197.5695343017578
Gradient for shared_block.0.linear.bias: 299.53973388671875
Gradient for shared_block.1.linear.weight: 1055.304931640625
Gradient for shared_block.1.linear.bias: 83.13224792480469
Gradient for shared_block.2.linear.weight: 309.8071594238281
Gradient for shared_block.2.linear.bias: 24.08110237121582
Gradient for shared_block.3.linear.weight: 99.29840087890625
Gradient for shared_block.3.linear.bias: 8.160624504089355
Gradient for shared_block.4.linear.weight: 34.2642707824707
Gradient for shared_block.4.linear.bias: 2.782740592956543
Gradient for shared_block.5.linear.weight: 12.492493629455566
Gradient for shared_block.5.linear.bias: 0.992375910282135
Gradient for shared_block.6.linear.weight: 5.285460472106934
Gradient for shared_block.6.linear.bias: 0.5638726353645325
Gradient for unique_block.0.linear.weight: 35.3737907409668
Gradient for unique_block.0.linear.bias: 7.817531585693359
Gradient for unique_block.1.linear.weight: 547.8849487304688
Gradient for unique_block.1.linear.bias: 79.13720703125
Gradient for output_layer.weight: 50.73244094848633
Gradient for output_layer.bias: 8.04379653930664
Image 1  /1000; epoch 37  /100000 processed.   Gradient for shared_block.0.linear.weight: 202.9092254638672
Gradient for shared_block.0.linear.bias: 307.6353759765625
Gradient for shared_block.1.linear.weight: 1083.8267822265625
Gradient for shared_block.1.linear.bias: 85.37906646728516
Gradient for shared_block.2.linear.weight: 318.1803283691406
Gradient for shared_block.2.linear.bias: 24.731943130493164
Gradient for shared_block.3.linear.weight: 101.98213958740234
Gradient for shared_block.3.linear.bias: 8.381181716918945
Gradient for shared_block.4.linear.weight: 35.19033432006836
Gradient for shared_block.4.linear.bias: 2.857949733734131
Gradient for shared_block.5.linear.weight: 12.83012866973877
Gradient for shared_block.5.linear.bias: 1.01919686794281
Gradient for shared_block.6.linear.weight: 5.428310871124268
Gradient for shared_block.6.linear.bias: 0.5791124105453491
Gradient for unique_block.0.linear.weight: 36.32984161376953
Gradient for unique_block.0.linear.bias: 8.028816223144531
Gradient for unique_block.1.linear.weight: 562.6926879882812
Gradient for unique_block.1.linear.bias: 81.27604675292969
Gradient for output_layer.weight: 52.10358810424805
Gradient for output_layer.bias: 8.26119613647461
Image 1  /1000; epoch 38  /100000 processed.   Gradient for shared_block.0.linear.weight: 208.2489471435547
Gradient for shared_block.0.linear.bias: 315.7310485839844
Gradient for shared_block.1.linear.weight: 1112.348388671875
Gradient for shared_block.1.linear.bias: 87.62588500976562
Gradient for shared_block.2.linear.weight: 326.5534973144531
Gradient for shared_block.2.linear.bias: 25.38278579711914
Gradient for shared_block.3.linear.weight: 104.66587829589844
Gradient for shared_block.3.linear.bias: 8.601738929748535
Gradient for shared_block.4.linear.weight: 36.11639404296875
Gradient for shared_block.4.linear.bias: 2.933159112930298
Gradient for shared_block.5.linear.weight: 13.167764663696289
Gradient for shared_block.5.linear.bias: 1.0460178852081299
Gradient for shared_block.6.linear.weight: 5.571161270141602
Gradient for shared_block.6.linear.bias: 0.5943522453308105
Gradient for unique_block.0.linear.weight: 37.285888671875
Gradient for unique_block.0.linear.bias: 8.240100860595703
Gradient for unique_block.1.linear.weight: 577.5003662109375
Gradient for unique_block.1.linear.bias: 83.4148941040039
Gradient for output_layer.weight: 53.474735260009766
Gradient for output_layer.bias: 8.478596687316895
Image 1  /1000; epoch 39  /100000 processed.   Gradient for shared_block.0.linear.weight: 213.5886688232422
Gradient for shared_block.0.linear.bias: 323.82672119140625
Gradient for shared_block.1.linear.weight: 1140.8702392578125
Gradient for shared_block.1.linear.bias: 89.8727035522461
Gradient for shared_block.2.linear.weight: 334.9266662597656
Gradient for shared_block.2.linear.bias: 26.03362464904785
Gradient for shared_block.3.linear.weight: 107.34962463378906
Gradient for shared_block.3.linear.bias: 8.822296142578125
Gradient for shared_block.4.linear.weight: 37.042457580566406
Gradient for shared_block.4.linear.bias: 3.0083682537078857
Gradient for shared_block.5.linear.weight: 13.505399703979492
Gradient for shared_block.5.linear.bias: 1.0728387832641602
Gradient for shared_block.6.linear.weight: 5.714011192321777
Gradient for shared_block.6.linear.bias: 0.609592080116272
Gradient for unique_block.0.linear.weight: 38.241939544677734
Gradient for unique_block.0.linear.bias: 8.451385498046875
Gradient for unique_block.1.linear.weight: 592.30810546875
Gradient for unique_block.1.linear.bias: 85.5537338256836
Gradient for output_layer.weight: 54.845882415771484
Gradient for output_layer.bias: 8.695996284484863
Image 1  /1000; epoch 40  /100000 processed.   Gradient for shared_block.0.linear.weight: 218.9283905029297
Gradient for shared_block.0.linear.bias: 331.9223937988281
Gradient for shared_block.1.linear.weight: 1169.3919677734375
Gradient for shared_block.1.linear.bias: 92.11952209472656
Gradient for shared_block.2.linear.weight: 343.2998352050781
Gradient for shared_block.2.linear.bias: 26.684465408325195
Gradient for shared_block.3.linear.weight: 110.03336334228516
Gradient for shared_block.3.linear.bias: 9.042853355407715
Gradient for shared_block.4.linear.weight: 37.9685173034668
Gradient for shared_block.4.linear.bias: 3.0835773944854736
Gradient for shared_block.5.linear.weight: 13.843033790588379
Gradient for shared_block.5.linear.bias: 1.09965980052948
Gradient for shared_block.6.linear.weight: 5.856861591339111
Gradient for shared_block.6.linear.bias: 0.6248318552970886
Gradient for unique_block.0.linear.weight: 39.1979866027832
Gradient for unique_block.0.linear.bias: 8.662670135498047
Gradient for unique_block.1.linear.weight: 607.1157836914062
Gradient for unique_block.1.linear.bias: 87.69258117675781
Gradient for output_layer.weight: 56.2170295715332
Gradient for output_layer.bias: 8.913395881652832
Image 1  /1000; epoch 41  /100000 processed.   Gradient for shared_block.0.linear.weight: 224.2681121826172
Gradient for shared_block.0.linear.bias: 340.0180358886719
Gradient for shared_block.1.linear.weight: 1197.9136962890625
Gradient for shared_block.1.linear.bias: 94.36634063720703
Gradient for shared_block.2.linear.weight: 351.6730041503906
Gradient for shared_block.2.linear.bias: 27.33530616760254
Gradient for shared_block.3.linear.weight: 112.71710205078125
Gradient for shared_block.3.linear.bias: 9.263410568237305
Gradient for shared_block.4.linear.weight: 38.89458084106445
Gradient for shared_block.4.linear.bias: 3.1587865352630615
Gradient for shared_block.5.linear.weight: 14.180668830871582
Gradient for shared_block.5.linear.bias: 1.1264806985855103
Gradient for shared_block.6.linear.weight: 5.999711990356445
Gradient for shared_block.6.linear.bias: 0.6400716304779053
Gradient for unique_block.0.linear.weight: 40.15403366088867
Gradient for unique_block.0.linear.bias: 8.873954772949219
Gradient for unique_block.1.linear.weight: 621.9234619140625
Gradient for unique_block.1.linear.bias: 89.8314208984375
Gradient for output_layer.weight: 57.58817672729492
Gradient for output_layer.bias: 9.130796432495117
Image 1  /1000; epoch 42  /100000 processed.   Gradient for shared_block.0.linear.weight: 229.60781860351562
Gradient for shared_block.0.linear.bias: 348.1137390136719
Gradient for shared_block.1.linear.weight: 1226.435546875
Gradient for shared_block.1.linear.bias: 96.61315155029297
Gradient for shared_block.2.linear.weight: 360.0461730957031
Gradient for shared_block.2.linear.bias: 27.986148834228516
Gradient for shared_block.3.linear.weight: 115.40084075927734
Gradient for shared_block.3.linear.bias: 9.483968734741211
Gradient for shared_block.4.linear.weight: 39.820640563964844
Gradient for shared_block.4.linear.bias: 3.2339956760406494
Gradient for shared_block.5.linear.weight: 14.518303871154785
Gradient for shared_block.5.linear.bias: 1.15330171585083
Gradient for shared_block.6.linear.weight: 6.142562389373779
Gradient for shared_block.6.linear.bias: 0.6553114652633667
Gradient for unique_block.0.linear.weight: 41.110084533691406
Gradient for unique_block.0.linear.bias: 9.08523941040039
Gradient for unique_block.1.linear.weight: 636.731201171875
Gradient for unique_block.1.linear.bias: 91.97026062011719
Gradient for output_layer.weight: 58.95932388305664
Gradient for output_layer.bias: 9.348196029663086
Image 1  /1000; epoch 43  /100000 processed.   Gradient for shared_block.0.linear.weight: 234.94754028320312
Gradient for shared_block.0.linear.bias: 356.20941162109375
Gradient for shared_block.1.linear.weight: 1254.957275390625
Gradient for shared_block.1.linear.bias: 98.85997772216797
Gradient for shared_block.2.linear.weight: 368.4193420410156
Gradient for shared_block.2.linear.bias: 28.63698959350586
Gradient for shared_block.3.linear.weight: 118.08457946777344
Gradient for shared_block.3.linear.bias: 9.7045259475708
Gradient for shared_block.4.linear.weight: 40.746700286865234
Gradient for shared_block.4.linear.bias: 3.3092048168182373
Gradient for shared_block.5.linear.weight: 14.855938911437988
Gradient for shared_block.5.linear.bias: 1.18012273311615
Gradient for shared_block.6.linear.weight: 6.285412311553955
Gradient for shared_block.6.linear.bias: 0.6705512404441833
Gradient for unique_block.0.linear.weight: 42.066131591796875
Gradient for unique_block.0.linear.bias: 9.296524047851562
Gradient for unique_block.1.linear.weight: 651.5388793945312
Gradient for unique_block.1.linear.bias: 94.1091079711914
Gradient for output_layer.weight: 60.33047103881836
Gradient for output_layer.bias: 9.565595626831055
Image 1  /1000; epoch 44  /100000 processed.   Gradient for shared_block.0.linear.weight: 240.28726196289062
Gradient for shared_block.0.linear.bias: 364.3050842285156
Gradient for shared_block.1.linear.weight: 1283.47900390625
Gradient for shared_block.1.linear.bias: 101.10679626464844
Gradient for shared_block.2.linear.weight: 376.7925109863281
Gradient for shared_block.2.linear.bias: 29.28782844543457
Gradient for shared_block.3.linear.weight: 120.76832580566406
Gradient for shared_block.3.linear.bias: 9.925084114074707
Gradient for shared_block.4.linear.weight: 41.67276382446289
Gradient for shared_block.4.linear.bias: 3.3844141960144043
Gradient for shared_block.5.linear.weight: 15.193573951721191
Gradient for shared_block.5.linear.bias: 1.2069436311721802
Gradient for shared_block.6.linear.weight: 6.428262710571289
Gradient for shared_block.6.linear.bias: 0.685791015625
Gradient for unique_block.0.linear.weight: 43.022178649902344
Gradient for unique_block.0.linear.bias: 9.507808685302734
Gradient for unique_block.1.linear.weight: 666.3466186523438
Gradient for unique_block.1.linear.bias: 96.2479476928711
Gradient for output_layer.weight: 61.70161819458008
Gradient for output_layer.bias: 9.782995223999023
Image 1  /1000; epoch 45  /100000 processed.   Gradient for shared_block.0.linear.weight: 245.62696838378906
Gradient for shared_block.0.linear.bias: 372.4007568359375
Gradient for shared_block.1.linear.weight: 1312.000732421875
Gradient for shared_block.1.linear.bias: 103.35360717773438
Gradient for shared_block.2.linear.weight: 385.1656799316406
Gradient for shared_block.2.linear.bias: 29.938671112060547
Gradient for shared_block.3.linear.weight: 123.45206451416016
Gradient for shared_block.3.linear.bias: 10.145641326904297
Gradient for shared_block.4.linear.weight: 42.59882354736328
Gradient for shared_block.4.linear.bias: 3.459623336791992
Gradient for shared_block.5.linear.weight: 15.531208992004395
Gradient for shared_block.5.linear.bias: 1.2337646484375
Gradient for shared_block.6.linear.weight: 6.571113109588623
Gradient for shared_block.6.linear.bias: 0.7010308504104614
Gradient for unique_block.0.linear.weight: 43.97822952270508
Gradient for unique_block.0.linear.bias: 9.719093322753906
Gradient for unique_block.1.linear.weight: 681.154296875
Gradient for unique_block.1.linear.bias: 98.38678741455078
Gradient for output_layer.weight: 63.0727653503418
Gradient for output_layer.bias: 10.000395774841309
Image 1  /1000; epoch 46  /100000 processed.   Gradient for shared_block.0.linear.weight: 250.96669006347656
Gradient for shared_block.0.linear.bias: 380.49639892578125
Gradient for shared_block.1.linear.weight: 1340.5224609375
Gradient for shared_block.1.linear.bias: 105.60043334960938
Gradient for shared_block.2.linear.weight: 393.5388488769531
Gradient for shared_block.2.linear.bias: 30.589509963989258
Gradient for shared_block.3.linear.weight: 126.13580322265625
Gradient for shared_block.3.linear.bias: 10.366198539733887
Gradient for shared_block.4.linear.weight: 43.52488708496094
Gradient for shared_block.4.linear.bias: 3.53483247756958
Gradient for shared_block.5.linear.weight: 15.868844032287598
Gradient for shared_block.5.linear.bias: 1.2605855464935303
Gradient for shared_block.6.linear.weight: 6.713963508605957
Gradient for shared_block.6.linear.bias: 0.7162706255912781
Gradient for unique_block.0.linear.weight: 44.93427658081055
Gradient for unique_block.0.linear.bias: 9.930377006530762
Gradient for unique_block.1.linear.weight: 695.9620361328125
Gradient for unique_block.1.linear.bias: 100.525634765625
Gradient for output_layer.weight: 64.44390869140625
Gradient for output_layer.bias: 10.217795372009277
Image 1  /1000; epoch 47  /100000 processed.   Gradient for shared_block.0.linear.weight: 256.306396484375
Gradient for shared_block.0.linear.bias: 388.59210205078125
Gradient for shared_block.1.linear.weight: 1369.0443115234375
Gradient for shared_block.1.linear.bias: 107.84725189208984
Gradient for shared_block.2.linear.weight: 401.9120178222656
Gradient for shared_block.2.linear.bias: 31.2403507232666
Gradient for shared_block.3.linear.weight: 128.81954956054688
Gradient for shared_block.3.linear.bias: 10.586755752563477
Gradient for shared_block.4.linear.weight: 44.45094680786133
Gradient for shared_block.4.linear.bias: 3.610041618347168
Gradient for shared_block.5.linear.weight: 16.206478118896484
Gradient for shared_block.5.linear.bias: 1.28740656375885
Gradient for shared_block.6.linear.weight: 6.856813907623291
Gradient for shared_block.6.linear.bias: 0.7315105199813843
Gradient for unique_block.0.linear.weight: 45.890323638916016
Gradient for unique_block.0.linear.bias: 10.14166259765625
Gradient for unique_block.1.linear.weight: 710.7697143554688
Gradient for unique_block.1.linear.bias: 102.66447448730469
Gradient for output_layer.weight: 65.81505584716797
Gradient for output_layer.bias: 10.435194969177246
Image 1  /1000; epoch 48  /100000 processed.   Gradient for shared_block.0.linear.weight: 261.6461181640625
Gradient for shared_block.0.linear.bias: 396.687744140625
Gradient for shared_block.1.linear.weight: 1397.5660400390625
Gradient for shared_block.1.linear.bias: 110.09406280517578
Gradient for shared_block.2.linear.weight: 410.28515625
Gradient for shared_block.2.linear.bias: 31.891191482543945
Gradient for shared_block.3.linear.weight: 131.50328063964844
Gradient for shared_block.3.linear.bias: 10.807312965393066
Gradient for shared_block.4.linear.weight: 45.377010345458984
Gradient for shared_block.4.linear.bias: 3.685250759124756
Gradient for shared_block.5.linear.weight: 16.544113159179688
Gradient for shared_block.5.linear.bias: 1.31422758102417
Gradient for shared_block.6.linear.weight: 6.999663829803467
Gradient for shared_block.6.linear.bias: 0.7467502355575562
Gradient for unique_block.0.linear.weight: 46.846370697021484
Gradient for unique_block.0.linear.bias: 10.352947235107422
Gradient for unique_block.1.linear.weight: 725.577392578125
Gradient for unique_block.1.linear.bias: 104.8033218383789
Gradient for output_layer.weight: 67.18620300292969
Gradient for output_layer.bias: 10.652595520019531
Image 1  /1000; epoch 49  /100000 processed.   Gradient for shared_block.0.linear.weight: 266.98583984375
Gradient for shared_block.0.linear.bias: 404.7834167480469
Gradient for shared_block.1.linear.weight: 1426.087890625
Gradient for shared_block.1.linear.bias: 112.34088897705078
Gradient for shared_block.2.linear.weight: 418.6583557128906
Gradient for shared_block.2.linear.bias: 32.542030334472656
Gradient for shared_block.3.linear.weight: 134.18702697753906
Gradient for shared_block.3.linear.bias: 11.027870178222656
Gradient for shared_block.4.linear.weight: 46.303070068359375
Gradient for shared_block.4.linear.bias: 3.7604598999023438
Gradient for shared_block.5.linear.weight: 16.88174819946289
Gradient for shared_block.5.linear.bias: 1.3410484790802002
Gradient for shared_block.6.linear.weight: 7.142514228820801
Gradient for shared_block.6.linear.bias: 0.7619900703430176
Gradient for unique_block.0.linear.weight: 47.80242156982422
Gradient for unique_block.0.linear.bias: 10.564231872558594
Gradient for unique_block.1.linear.weight: 740.3851318359375
Gradient for unique_block.1.linear.bias: 106.9421615600586
Gradient for output_layer.weight: 68.5573501586914
Gradient for output_layer.bias: 10.8699951171875
Image 1  /1000; epoch 50  /100000 processed.   Gradient for shared_block.0.linear.weight: 272.3255310058594
Gradient for shared_block.0.linear.bias: 412.87908935546875
Gradient for shared_block.1.linear.weight: 1454.609619140625
Gradient for shared_block.1.linear.bias: 114.58769989013672
Gradient for shared_block.2.linear.weight: 427.031494140625
Gradient for shared_block.2.linear.bias: 33.19287109375
Gradient for shared_block.3.linear.weight: 136.8707733154297
Gradient for shared_block.3.linear.bias: 11.248428344726562
Gradient for shared_block.4.linear.weight: 47.22913360595703
Gradient for shared_block.4.linear.bias: 3.8356692790985107
Gradient for shared_block.5.linear.weight: 17.219385147094727
Gradient for shared_block.5.linear.bias: 1.36786949634552
Gradient for shared_block.6.linear.weight: 7.285364627838135
Gradient for shared_block.6.linear.bias: 0.777229905128479
Gradient for unique_block.0.linear.weight: 48.75846862792969
Gradient for unique_block.0.linear.bias: 10.775516510009766
Gradient for unique_block.1.linear.weight: 755.1928100585938
Gradient for unique_block.1.linear.bias: 109.08100891113281
Gradient for output_layer.weight: 69.92849731445312
Gradient for output_layer.bias: 11.087394714355469
Image 1  /1000; epoch 51  /100000 processed.   Stopping early: no improvement after 50 meta-updates.
Training for image 1 stopped early at epoch 51.
C:\Users\pimde\OneDrive\Documents\GitHub\2AMM20-MetaLearningSharedParameters\finetune.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load("saved_models/finetuned_model.pth")